{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from create_matrix import *\n",
    "\n",
    "\n",
    "def get_tensor(df, start, stop):\n",
    "#     start, stop = 1, 13\n",
    "    energy_cols = np.array(\n",
    "        [['%s_%d' % (appliance, month) for month in range(start, stop)] for appliance in APPLIANCES_ORDER]).flatten()\n",
    "\n",
    "    dfc = df.copy()\n",
    "\n",
    "    df = dfc[energy_cols]\n",
    "\n",
    "    tensor = df.values.reshape((len(df), 7, stop - start))\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# def create_region_df_dfc_static(region, year):\n",
    "#     df, dfc = create_matrix_single_region(region, year)\n",
    "#     tensor = get_tensor(df, start, stop)\n",
    "#     static_region = df[['area', 'total_occupants', 'num_rooms']].copy()\n",
    "#     static_region['area'] = static_region['area'].div(4000)\n",
    "#     static_region['total_occupants'] = static_region['total_occupants'].div(8)\n",
    "#     static_region['num_rooms'] = static_region['num_rooms'].div(8)\n",
    "#     static_region = static_region.values\n",
    "#     return df, dfc, tensor, static_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_region_df_dfc_static(region, year, start=1, stop=13):\n",
    "    df, dfc = create_matrix_single_region(region, year)\n",
    "    tensor = get_tensor(df, start, stop)\n",
    "    static_region = df[['area', 'total_occupants', 'num_rooms']].copy()\n",
    "    static_region['area'] = static_region['area'].div(4000)\n",
    "    static_region['total_occupants'] = static_region['total_occupants'].div(8)\n",
    "    static_region['num_rooms'] = static_region['num_rooms'].div(8)\n",
    "    static_region = static_region.values\n",
    "    return df, dfc, tensor, static_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, dfc,tensor,static_region = create_region_df_dfc_static('SanDiego', 2014, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 7, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_store = pickle.load(open(os.path.expanduser('~/git/scalable-nilm/aaai18/predictions/H/transfer/case-2/True/True/Austin-SanDiego-0-10.0.pkl'), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(H_store['Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This module saves the A matrix learnt using P = HAS, for various\n",
    "combinations of parameters, such as number of iterations,\n",
    "number of season and home factors, Lambda\n",
    "\n",
    "It can be run as:\n",
    "\n",
    "### Template\n",
    ">>>python save_A_graph_laplacian.py case region\n",
    "\n",
    "### Example\n",
    ">>> python save_A_graph_laplacian.py 2 Austin\n",
    "\"\"\"\n",
    "\n",
    "from common import create_region_df_dfc_static\n",
    "from create_matrix import *\n",
    "from tensor_custom_core_all import *\n",
    "import datetime\n",
    "from common import compute_rmse_fraction, contri, get_tensor, create_region_df_dfc_static\n",
    "\n",
    "appliance_index = {appliance: APPLIANCES_ORDER.index(appliance) for appliance in APPLIANCES_ORDER}\n",
    "APPLIANCES = ['fridge', 'hvac', 'wm', 'mw', 'oven', 'dw']\n",
    "year = 2014\n",
    "\n",
    "# case, source, constant_use, start, stop = sys.argv[1:]\n",
    "case = 2\n",
    "source = 'Austin'\n",
    "constant_use = True\n",
    "start = 5\n",
    "stop = 11\n",
    "case = int(case)\n",
    "start = int(start)\n",
    "stop = int(stop)\n",
    "source_df, source_dfc, source_tensor, source_static = create_region_df_dfc_static(source, year, start, stop)\n",
    "\n",
    "# # using cosine similarity to compute L\n",
    "source_L = get_L(source_static)\n",
    "\n",
    "# Seasonal constant constraints\n",
    "if constant_use == 'True':\n",
    "    T_constant = np.ones(stop-start).reshape(-1,1)\n",
    "else:\n",
    "    T_constant = None\n",
    "# End\n",
    "\n",
    "pred = {}\n",
    "n_splits = 10\n",
    "\n",
    "algo = 'adagrad'\n",
    "cost = 'l21'\n",
    "\n",
    "for appliance in APPLIANCES_ORDER:\n",
    "    pred[appliance] = []\n",
    "best_params_global = {}\n",
    "A_store = {}\n",
    "err_store = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_HAT_adagrad_graph(case, tensor, L, num_home_factors, num_season_factors, num_iter=2000, lr=0.01, dis=False,\n",
    "                            lam=1, random_seed=0, eps=1e-8, A_known = None, T_known = None):\n",
    "    np.random.seed(random_seed)\n",
    "    cost = cost_graph_laplacian\n",
    "    # if A_known is not None:\n",
    "    #     # Don't need to learn A\n",
    "    #     args_num = [0, 2]\n",
    "    # else:\n",
    "    #     args_num = [0, 1, 2]\n",
    "    args_num=[0,1,2]\n",
    "    mg = multigrad(cost, argnums=args_num)\n",
    "\n",
    "    params = {}\n",
    "    params['M'], params['N'], params['O'] = tensor.shape\n",
    "    params['a'] = num_home_factors\n",
    "    params['b'] = num_season_factors\n",
    "    H_dim_chars = list(cases[case]['HA'].split(\",\")[0].strip())\n",
    "    H_dim = tuple(params[x] for x in H_dim_chars)\n",
    "    A_dim_chars = list(cases[case]['HA'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    A_dim = tuple(params[x] for x in A_dim_chars)\n",
    "    T_dim_chars = list(cases[case]['HAT'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    T_dim = tuple(params[x] for x in T_dim_chars)\n",
    "\n",
    "    H = np.random.rand(*H_dim)\n",
    "    \n",
    "    # if A_known is not None:\n",
    "    #     A = A_known\n",
    "    # else:\n",
    "    #     A = np.random.rand(*A_dim)\n",
    "    #     sum_square_gradients_A = np.zeros_like(A)\n",
    "    A = np.random.rand(*A_dim)\n",
    "    if A_known is not None:\n",
    "        A = set_known(A, A_known)\n",
    "    sum_square_gradients_A = np.zeros_like(A)\n",
    "    \n",
    "    \n",
    "    T = np.random.rand(*T_dim)\n",
    "    \n",
    "    sum_square_gradients_H = np.zeros_like(H)\n",
    "    sum_square_gradients_T = np.zeros_like(T)\n",
    "    Hs = [H.copy()]\n",
    "    Ts = [T.copy()]\n",
    "    As = [A.copy()]\n",
    "    costs = [cost(H, A, T, L, tensor, lam, case)]\n",
    "    HATs = [multiply_case(H, A, T, case)]\n",
    "\n",
    "    \n",
    "\n",
    "    # GD procedure\n",
    "    for i in range(num_iter):\n",
    "        # if A_known is not None:\n",
    "        #     del_h,  del_t = mg(H, A, T, L, tensor, lam, case)\n",
    "        # else:\n",
    "        #     del_h, del_a, del_t = mg(H, A, T, L, tensor, lam, case)\n",
    "        #     sum_square_gradients_A += eps + np.square(del_a)\n",
    "        #     lr_a = np.divide(lr, np.sqrt(sum_square_gradients_A))\n",
    "        #     A -= lr_a * del_a\n",
    "        del_h, del_a, del_t = mg(H, A, T, L, tensor, lam, case)\n",
    "        sum_square_gradients_A += eps + np.square(del_a)\n",
    "        lr_a = np.divide(lr, np.sqrt(sum_square_gradients_A))\n",
    "        A -= lr_a * del_a\n",
    "        \n",
    "        sum_square_gradients_H += eps + np.square(del_h)\n",
    "        sum_square_gradients_T += eps + np.square(del_t)\n",
    "\n",
    "        lr_h = np.divide(lr, np.sqrt(sum_square_gradients_H))\n",
    "        lr_t = np.divide(lr, np.sqrt(sum_square_gradients_T))\n",
    "\n",
    "        H -= lr_h * del_h\n",
    "        T -= lr_t * del_t\n",
    "\n",
    "        if T_known is not None:\n",
    "            T = set_known(T, T_known)\n",
    "        if A_known is not None:\n",
    "            A = set_known(A, A_known)\n",
    "\n",
    "        # Projection to non-negative space\n",
    "        H[H < 0] = 1e-8\n",
    "        A[A < 0] = 1e-8\n",
    "        T[T < 0] = 1e-8\n",
    "\n",
    "        As.append(A.copy())\n",
    "        Ts.append(T.copy())\n",
    "        Hs.append(H.copy())\n",
    "\n",
    "        costs.append(cost(H, A, T, L, tensor, lam, case))\n",
    "\n",
    "        HATs.append(multiply_case(H, A, T, case))\n",
    "        if i % 500 == 0:\n",
    "            if dis:\n",
    "                print(cost(H, A, T, L, tensor, lam, case))\n",
    "    return H, A, T, Hs, As, Ts, HATs, costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "2017-09-06 13:12:02.454425\n",
      "--------------------------------------------------------------------------------\n",
      "(533, 7, 6)\n",
      "[[ 5.22935724  4.85548461]\n",
      " [ 6.80357525  7.61464996]\n",
      " [ 8.34935916  8.24746994]\n",
      " [ 8.84420421  9.45900976]\n",
      " [ 6.81484295  7.192159  ]\n",
      " [ 5.91437255  4.81921679]]\n",
      "(0.1, 2, 2, 0.001, 100, 541.81357583517922)\n",
      "(0.1, 2, 2, 0.001, 300, 346.00035599544066)\n",
      "(0.1, 2, 2, 0.001, 500, 221.38237646713816)\n",
      "(0.1, 2, 2, 0.001, 700, 183.16802620818515)\n",
      "(0.1, 2, 2, 0.001, 900, 172.04770698612413)\n",
      "(0.1, 2, 2, 0.001, 1100, 166.79895521698737)\n",
      "(0.1, 2, 2, 0.001, 1300, 163.57769186177509)\n"
     ]
    }
   ],
   "source": [
    "max_num_iterations = 1300\n",
    "for learning_rate_cv in [0.1]:\n",
    "    A_store[learning_rate_cv] = {}\n",
    "    err_store[learning_rate_cv] = {}\n",
    "    for num_season_factors_cv in range(2, 3):\n",
    "\n",
    "        A_store[learning_rate_cv][num_season_factors_cv] = {}\n",
    "        err_store[learning_rate_cv][num_season_factors_cv] = {}\n",
    "        for num_home_factors_cv in range(2, 3):\n",
    "            if case == 4:\n",
    "                if num_home_factors_cv != num_season_factors_cv:\n",
    "                    print(\"Case 4 needs equal # dimensions. Skipping\")\n",
    "                    continue\n",
    "            A_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv] = {}\n",
    "            err_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv] = {}\n",
    "            for lam_cv in [0.001]:\n",
    "                print(\"-\"*80)\n",
    "                print(datetime.datetime.now())\n",
    "                print(\"-\" * 80)\n",
    "                sys.stdout.flush()\n",
    "                A_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv][lam_cv] = {}\n",
    "                err_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv][lam_cv] = {}\n",
    "                \n",
    "                print source_tensor.shape\n",
    "                H_source, A_source, T_source, Hs, As, Ts, HATs, costs = learn_HAT_adagrad_graph(case, source_tensor,\n",
    "                                                                                                source_L,\n",
    "                                                                                                num_home_factors_cv,\n",
    "                                                                                                num_season_factors_cv,\n",
    "                                                                                                num_iter=max_num_iterations,\n",
    "                                                                                                lr=learning_rate_cv, dis=False,\n",
    "                                                                                                lam=lam_cv,\n",
    "                                                                                                T_known=T_constant)\n",
    "                \n",
    "                \n",
    "                print T_source\n",
    "                for num_iterations in range(100, 1400, 200):\n",
    "                    A_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv][lam_cv][num_iterations] = As[num_iterations]\n",
    "                    print(learning_rate_cv, num_season_factors_cv, num_home_factors_cv, lam_cv, num_iterations, costs[num_iterations])\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                err = {}\n",
    "                for num_iterations in range(100, 1400, 200):\n",
    "                    err[num_iterations] = {}\n",
    "                    for appliance in APPLIANCES_ORDER:\n",
    "                        pred[appliance] = []\n",
    "                    for appliance in APPLIANCES_ORDER:\n",
    "                        pred[appliance].append(pd.DataFrame(HATs[num_iterations][:, appliance_index[appliance], :], index=source_df.index))\n",
    "                    for appliance in APPLIANCES_ORDER:\n",
    "                        pred[appliance] = pd.DataFrame(pd.concat(pred[appliance]))\n",
    "\n",
    "                    for appliance in APPLIANCES_ORDER[1:]:\n",
    "                        prediction = pred[appliance]\n",
    "                        if appliance == \"hvac\":\n",
    "                            prediction = prediction[range(5-start, 11-start)]\n",
    "                        err[num_iterations][appliance] = \\\n",
    "                            compute_rmse_fraction(appliance, prediction, source, start, stop)[2]\n",
    "                    # print(\"Computed for: {}\".format())\n",
    "\n",
    "                    err_weight = {}\n",
    "                    for appliance in APPLIANCES_ORDER[1:]:\n",
    "                        err_weight[appliance] = err[num_iterations][appliance]*contri[source][appliance]\n",
    "                    mean_err = pd.Series(err_weight).sum()\n",
    "                    err_store[learning_rate_cv][num_season_factors_cv][num_home_factors_cv][lam_cv][num_iterations] = mean_err\n",
    "\n",
    "# pickle.dump(A_store, open('../predictions/case-{}-graph_{}_{}_{}_{}_As.pkl'.format(case, source, constant_use, start, stop), 'w'))\n",
    "# pickle.dump(err_store, open('../predictions/case-{}-graph_{}_{}_{}_{}_errs.pkl'.format(case, source, constant_use, start, stop), 'w'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
