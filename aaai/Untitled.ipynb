{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "from create_matrix import *\n",
    "import os\n",
    "import sys\n",
    "from tensor_custom_core import *\n",
    "from create_matrix import *\n",
    "from tensor_custom_core import *\n",
    "from degree_days import dds\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from common import compute_rmse_fraction\n",
    "from common import compute_rmse\n",
    "\n",
    "appliance_index = {appliance: APPLIANCES_ORDER.index(appliance) for appliance in APPLIANCES_ORDER}\n",
    "APPLIANCES = ['fridge', 'hvac', 'wm', 'mw', 'oven', 'dw']\n",
    "year = 2014\n",
    "n_splits = 10\n",
    "case=2\n",
    "a=2\n",
    "cost='abs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def un_normalize(x, maximum, minimum):\n",
    "    return (maximum - minimum) * x + minimum\n",
    "\n",
    "def get_tensor(df, dfc):\n",
    "    start, stop = 1, 13\n",
    "    energy_cols = np.array(\n",
    "        [['%s_%d' % (appliance, month) for month in range(start, stop)] for appliance in APPLIANCES_ORDER]).flatten()\n",
    "\n",
    "    static_cols = ['area', 'total_occupants', 'num_rooms']\n",
    "    static_df = df[static_cols]\n",
    "    static_df = static_df.div(static_df.max())\n",
    "    weather_values = np.array(dds[2014][region][start - 1:stop - 1]).reshape(-1, 1)\n",
    "\n",
    "    dfc = df.copy()\n",
    "\n",
    "    df = dfc[energy_cols]\n",
    "    col_max = df.max().max()\n",
    "    col_min = df.min().min()\n",
    "    # df = (1.0 * (df - col_min)) / (col_max - col_min)\n",
    "    tensor = df.values.reshape((len(df), 7, stop - start))\n",
    "    M, N, O = tensor.shape\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region = \"SanDiego\"\n",
    "sd_df, sd_dfc = create_matrix_single_region(\"SanDiego\", year)\n",
    "sd_tensor = get_tensor(sd_df, sd_dfc)\n",
    "region = \"Austin\"\n",
    "au_df, au_dfc = create_matrix_single_region(\"Austin\", year)\n",
    "au_tensor = get_tensor(au_df, au_dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from numpy import linalg as LA\n",
    "from autograd import multigrad\n",
    "\n",
    "def cost_abs_reg(H, A, T, E_np_masked, case):\n",
    "    la = 0.5\n",
    "    HAT = multiply_case(H, A, T, case)\n",
    "    mask = ~np.isnan(E_np_masked)\n",
    "    error = (HAT - E_np_masked)[mask].flatten() + la * LA.norm(~np.isnan(H)) + la * LA.norm(~np.isnan(A)) + la * LA.norm(~np.isnan(T))\n",
    "    return np.sqrt((error ** 2).mean())\n",
    "\n",
    "def learn_HAT_reg(case, E_np_masked, a, b, num_iter=2000, lr=0.1, dis=False, cost_function='abs', H_known=None,\n",
    "              A_known=None, T_known=None, random_seed=0, random_mul_constant=1,\n",
    "              random_add_constant=0):\n",
    "    np.random.seed(random_seed)\n",
    "    if cost_function == 'abs':\n",
    "        cost = cost_abs_reg\n",
    "    else:\n",
    "        cost = cost_rel\n",
    "    mg = multigrad(cost, argnums=[0, 1, 2])\n",
    "\n",
    "    params = {}\n",
    "    params['M'], params['N'], params['O'] = E_np_masked.shape\n",
    "    params['a'] = a\n",
    "    params['b'] = b\n",
    "    H_dim_chars = list(cases[case]['HA'].split(\",\")[0].strip())\n",
    "    H_dim = tuple(params[x] for x in H_dim_chars)\n",
    "    A_dim_chars = list(cases[case]['HA'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    A_dim = tuple(params[x] for x in A_dim_chars)\n",
    "    T_dim_chars = list(cases[case]['HAT'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    T_dim = tuple(params[x] for x in T_dim_chars)\n",
    "    H = np.random.rand(*H_dim)*random_mul_constant+random_add_constant\n",
    "\n",
    "    A = np.random.rand(*A_dim)*random_mul_constant+random_add_constant\n",
    "    T = np.random.rand(*T_dim)*random_mul_constant+random_add_constant\n",
    "\n",
    "    # GD procedure\n",
    "    for i in range(num_iter):\n",
    "        del_h, del_a, del_t = mg(H, A, T, E_np_masked, case)\n",
    "        H -= lr * del_h\n",
    "        A -= lr * del_a\n",
    "        T -= lr * del_t\n",
    "        # Projection to known values\n",
    "        if H_known is not None:\n",
    "            H = set_known(H, H_known)\n",
    "        if A_known is not None:\n",
    "            A = set_known(A, A_known)\n",
    "        if T_known is not None:\n",
    "            T = set_known(T, T_known)\n",
    "        # Projection to non-negative space\n",
    "        H[H < 0] = 0\n",
    "        A[A < 0] = 0\n",
    "        T[T < 0] = 0\n",
    "        if i % 500 == 0:\n",
    "            if dis:\n",
    "                print(cost(H, A, T, E_np_masked, case))\n",
    "    return H, A, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal learning in SanDiego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed:  0\n",
      "training percentage:  10\n",
      "round:  0\n",
      "test_ix:  Int64Index([54, 203, 527, 1450], dtype='int64')\n",
      "round:  1\n",
      "test_ix:  Int64Index([1524, 1731, 2031, 2354], dtype='int64')\n",
      "round:  2\n",
      "test_ix:  Int64Index([2606, 3687, 3864, 3938], dtype='int64')\n",
      "round:  3\n",
      "test_ix:  Int64Index([4083, 4095, 4329, 4495], dtype='int64')\n",
      "round:  4\n",
      "test_ix:  Int64Index([4761, 4934, 5909, 5938], dtype='int64')\n",
      "round:  5\n",
      "test_ix:  Int64Index([6268, 6377, 6429, 6497], dtype='int64')\n",
      "round:  6\n",
      "test_ix:  Int64Index([6547, 7062, 7114, 7409], dtype='int64')\n",
      "round:  7\n",
      "test_ix:  Int64Index([7639, 8061, 8342, 8574], dtype='int64')\n",
      "round:  8\n",
      "test_ix:  Int64Index([8733, 9213, 9370, 9585], dtype='int64')\n",
      "round:  9\n",
      "test_ix:  Int64Index([9612, 9775, 9836], dtype='int64')\n",
      "training percentage:  20\n",
      "round:  0\n",
      "test_ix:  Int64Index([54, 203, 527, 1450], dtype='int64')\n",
      "round:  1\n",
      "test_ix:  Int64Index([1524, 1731, 2031, 2354], dtype='int64')\n",
      "round:  2\n",
      "test_ix:  Int64Index([2606, 3687, 3864, 3938], dtype='int64')\n",
      "round:  3\n",
      "test_ix:  Int64Index([4083, 4095, 4329, 4495], dtype='int64')\n",
      "round:  4\n",
      "test_ix:  Int64Index([4761, 4934, 5909, 5938], dtype='int64')\n",
      "round:  5\n",
      "test_ix:  Int64Index([6268, 6377, 6429, 6497], dtype='int64')\n",
      "round:  6\n",
      "test_ix:  Int64Index([6547, 7062, 7114, 7409], dtype='int64')\n",
      "round:  7\n",
      "test_ix:  Int64Index([7639, 8061, 8342, 8574], dtype='int64')\n",
      "round:  8\n",
      "test_ix:  Int64Index([8733, 9213, 9370, 9585], dtype='int64')\n",
      "round:  9\n",
      "test_ix:  Int64Index([9612, 9775, 9836], dtype='int64')\n",
      "training percentage:  30\n",
      "round:  0\n",
      "test_ix:  Int64Index([54, 203, 527, 1450], dtype='int64')\n",
      "round:  1\n",
      "test_ix:  Int64Index([1524, 1731, 2031, 2354], dtype='int64')\n",
      "round:  2\n",
      "test_ix:  Int64Index([2606, 3687, 3864, 3938], dtype='int64')\n",
      "round:  3\n",
      "test_ix:  Int64Index([4083, 4095, 4329, 4495], dtype='int64')\n",
      "round:  4\n",
      "test_ix:  Int64Index([4761, 4934, 5909, 5938], dtype='int64')\n",
      "round:  5\n",
      "test_ix:  Int64Index([6268, 6377, 6429, 6497], dtype='int64')\n",
      "round:  6\n",
      "test_ix:  Int64Index([6547, 7062, 7114, 7409], dtype='int64')\n",
      "round:  7\n",
      "test_ix:  Int64Index([7639, 8061, 8342, 8574], dtype='int64')\n",
      "round:  8\n",
      "test_ix:  Int64Index([8733, 9213, 9370, 9585], dtype='int64')\n",
      "round:  9\n",
      "test_ix:  Int64Index([9612, 9775, 9836], dtype='int64')\n",
      "training percentage:  40\n",
      "round:  0\n",
      "test_ix:  Int64Index([54, 203, 527, 1450], dtype='int64')\n",
      "round:  1\n",
      "test_ix:  Int64Index([1524, 1731, 2031, 2354], dtype='int64')\n",
      "round:  2\n",
      "test_ix:  Int64Index([2606, 3687, 3864, 3938], dtype='int64')\n",
      "round:  3\n",
      "test_ix:  Int64Index([4083, 4095, 4329, 4495], dtype='int64')\n",
      "round:  4\n",
      "test_ix:  Int64Index([4761, 4934, 5909, 5938], dtype='int64')\n",
      "round:  5\n",
      "test_ix:  Int64Index([6268, 6377, 6429, 6497], dtype='int64')\n",
      "round:  6\n",
      "test_ix:  Int64Index([6547, 7062, 7114, 7409], dtype='int64')\n",
      "round:  7\n",
      "test_ix:  Int64Index([7639, 8061, 8342, 8574], dtype='int64')\n",
      "round:  8\n",
      "test_ix:  Int64Index([8733, 9213, 9370, 9585], dtype='int64')\n",
      "round:  9\n",
      "test_ix:  Int64Index([9612, 9775, 9836], dtype='int64')\n",
      "training percentage:  50\n",
      "round:  0\n",
      "test_ix:  Int64Index([54, 203, 527, 1450], dtype='int64')\n",
      "round:  1\n",
      "test_ix:  Int64Index([1524, 1731, 2031, 2354], dtype='int64')\n",
      "round:  2\n",
      "test_ix:  Int64Index([2606, 3687, 3864, 3938], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "n_splits = 10\n",
    "case = 2\n",
    "a = 2\n",
    "b = 2\n",
    "cost = 'abs'\n",
    "\n",
    "for random_seed in range(10):\n",
    "    pred[random_seed] = {}\n",
    "    for appliance in APPLIANCES_ORDER:\n",
    "        pred[random_seed][appliance] = {f:[] for f in range(10, 110, 10)}\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "for random_seed in range(10):\n",
    "    print \"random seed: \", random_seed\n",
    "    for train_percentage in range(10, 110, 10):\n",
    "        print \"training percentage: \", train_percentage\n",
    "        rd = 0\n",
    "        for train_max, test in kf.split(sd_df):\n",
    "            print \"round: \", rd\n",
    "            rd += 1\n",
    "            \n",
    "            num_train = int((train_percentage*len(train_max)/100)+0.5)\n",
    "            num_test = len(test)\n",
    "            \n",
    "            # get the random training data from train_max based on then random seed\n",
    "            if train_percentage==100:\n",
    "                train = train_max\n",
    "            else:\n",
    "                train, _ = train_test_split(train_max, train_size = train_percentage/100.0, random_state=random_seed)\n",
    "            \n",
    "            # get the index of training and testing data\n",
    "            train_ix = sd_df.index[train]\n",
    "            test_ix = sd_df.index[test]\n",
    "            print \"test_ix: \", test_ix\n",
    "            \n",
    "            # create the tensor\n",
    "            train_test_ix = np.concatenate([test_ix, train_ix])\n",
    "            df_t, dfc_t = sd_df.ix[train_test_ix], sd_dfc.ix[train_test_ix]\n",
    "            tensor = get_tensor(df_t, dfc_t)\n",
    "            tensor_copy = tensor.copy()\n",
    "            # set the appliance consumption to be missing for testing data\n",
    "            tensor_copy[:num_test, 1:, :] = np.NaN\n",
    "            # do tensor factorization\n",
    "            H, A, T = learn_HAT(case, tensor_copy, a, b, num_iter=2000, lr=0.1, dis=False, cost_function=cost)\n",
    "            # get the prediction\n",
    "            HAT = multiply_case(H, A, T, case)\n",
    "            for appliance in APPLIANCES_ORDER:\n",
    "                pred[random_seed][appliance][train_percentage].append(pd.DataFrame(HAT[:num_test, appliance_index[appliance], :], index=test_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_reg = {}\n",
    "n_splits = 10\n",
    "case = 2\n",
    "a = 2\n",
    "cost = 'abs'\n",
    "\n",
    "for random_seed in range(10):\n",
    "    pred_reg[random_seed] = {}\n",
    "    for appliance in APPLIANCES_ORDER:\n",
    "        pred_reg[random_seed][appliance] = {f:[] for f in range(10, 110, 10)}\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "for random_seed in range(10):\n",
    "    print \"random seed: \", random_seed\n",
    "    for train_percentage in range(10, 110, 10):\n",
    "        print \"training percentage: \", train_percentage\n",
    "        rd = 0\n",
    "        for train_max, test in kf.split(sd_df):\n",
    "            print \"round: \", rd\n",
    "            rd += 1\n",
    "            \n",
    "            num_train = int((train_percentage*len(train_max)/100)+0.5)\n",
    "            num_test = len(test)\n",
    "            \n",
    "            # get the random training data from train_max based on then random seed\n",
    "            if train_percentage==100:\n",
    "                train = train_max\n",
    "            else:\n",
    "                train, _ = train_test_split(train_max, train_size = train_percentage/100.0, random_state=random_seed)\n",
    "            \n",
    "            # get the index of training and testing data\n",
    "            train_ix = sd_df.index[train]\n",
    "            test_ix = sd_df.index[test]\n",
    "            print \"test_ix: \", test_ix\n",
    "            \n",
    "            # create the tensor\n",
    "            train_test_ix = np.concatenate([test_ix, train_ix])\n",
    "            df_t, dfc_t = sd_df.ix[train_test_ix], sd_dfc.ix[train_test_ix]\n",
    "            tensor = get_tensor(df_t, dfc_t)\n",
    "            tensor_copy = tensor.copy()\n",
    "            # set the appliance consumption to be missing for testing data\n",
    "            tensor_copy[:num_test, 1:, :] = np.NaN\n",
    "            # do tensor factorization\n",
    "            H, A, T = learn_HAT_reg(case, tensor_copy, a, b, num_iter=2000, lr=0.1, dis=False, cost_function=cost)\n",
    "            # get the prediction\n",
    "            HAT = multiply_case(H, A, T, case)\n",
    "            for appliance in APPLIANCES_ORDER:\n",
    "                pred_reg[random_seed][appliance][train_percentage].append(pd.DataFrame(HAT[:num_test, appliance_index[appliance], :], index=test_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
