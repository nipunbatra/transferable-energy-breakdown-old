{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from create_matrix import *\n",
    "\n",
    "from tensor_custom_core import *\n",
    "from create_matrix import *\n",
    "from tensor_custom_core import *\n",
    "from degree_days import dds\n",
    "appliance_index = {appliance: APPLIANCES_ORDER.index(appliance) for appliance in APPLIANCES_ORDER}\n",
    "\n",
    "APPLIANCES = ['fridge', 'hvac', 'wm', 'mw', 'oven', 'dw']\n",
    "region = \"SanDiego\"\n",
    "year = 2014\n",
    "\n",
    "import os\n",
    "from degree_days import dds\n",
    "import autograd.numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def un_normalize(x, maximum, minimum):\n",
    "    return (maximum - minimum) * x + minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    start, stop = 1, 13\n",
    "    energy_cols = np.array(\n",
    "        [['%s_%d' % (appliance, month) for month in range(start, stop)] for appliance in APPLIANCES_ORDER]).flatten()\n",
    "\n",
    "    dfc = df.copy()\n",
    "\n",
    "    df = dfc[energy_cols]\n",
    "\n",
    "    tensor = df.values.reshape((len(df), 7, stop - start))\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def create_region_df_dfc_static(region, year):\n",
    "    df, dfc = create_matrix_single_region(region, year)\n",
    "    tensor = get_tensor(df)\n",
    "    static_region = df[['area', 'total_occupants', 'num_rooms']].copy()\n",
    "    static_region['area'] = static_region['area'].div(4000)\n",
    "    static_region['total_occupants'] = static_region['total_occupants'].div(8)\n",
    "    static_region['num_rooms'] = static_region['num_rooms'].div(8)\n",
    "    static_region =static_region.values\n",
    "    return df, dfc, tensor, static_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "au_df, au_dfc, au_tensor, au_static = create_region_df_dfc_static('Austin', year)\n",
    "sd_df, sd_dfc, sd_tensor, sd_static = create_region_df_dfc_static('SanDiego', year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd_agg = sd_df.loc[:, 'aggregate_1':'aggregate_12']\n",
    "au_agg = au_df.loc[:, 'aggregate_1':'aggregate_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd_agg = np.nan_to_num(sd_agg)\n",
    "au_agg = np.nan_to_num(au_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(x, y):\n",
    "    return np.linalg.norm(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "def get_L_NN(X):\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    n_sample, n_feature = X.shape\n",
    "    W = np.zeros((n_sample, n_sample))\n",
    "    for i in range(n_sample):\n",
    "        for j in indices[i]:\n",
    "            W[i][j] = 1\n",
    "            W[j][i] = 1\n",
    "    K = np.dot(W, np.ones((n_sample, n_sample)))\n",
    "    D = np.diag(np.diag(K))\n",
    "    return D - W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_graph_laplacian(H, A, T, L, E_np_masked, lam, case):\n",
    "    HAT = multiply_case(H, A, T, case)\n",
    "    mask = ~np.isnan(E_np_masked)\n",
    "    error_1 = (HAT - E_np_masked)[mask].flatten()\n",
    "    \n",
    "    HTL = np.dot(H.T, L)\n",
    "    HTLH = np.dot(HTL, H)\n",
    "    error_2 = np.trace(HTLH)\n",
    "    \n",
    "    return np.sqrt((error_1**2).mean()) + lam * error_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_HAT_adagrad_graph(case, E_np_masked, graph_L, a, b, num_iter=2000, lr=0.1, dis=False, graph_lam = 0, H_known=None,\n",
    "                      A_known=None, T_known=None, random_seed=0, eps=1e-8, penalty_coeff=0.0):\n",
    "\n",
    "    cost = cost_graph_laplacian\n",
    "    mg = multigrad(cost, argnums=[0, 1, 2])\n",
    "\n",
    "    params = {}\n",
    "    params['M'], params['N'], params['O'] = E_np_masked.shape\n",
    "    params['a'] = a\n",
    "    params['b'] = b\n",
    "    H_dim_chars = list(cases[case]['HA'].split(\",\")[0].strip())\n",
    "    H_dim = tuple(params[x] for x in H_dim_chars)\n",
    "    A_dim_chars = list(cases[case]['HA'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    A_dim = tuple(params[x] for x in A_dim_chars)\n",
    "    T_dim_chars = list(cases[case]['HAT'].split(\",\")[1].split(\"-\")[0].strip())\n",
    "    T_dim = tuple(params[x] for x in T_dim_chars)\n",
    "    \n",
    "    H = np.random.rand(*H_dim)\n",
    "    A = np.random.rand(*A_dim)\n",
    "    T = np.random.rand(*T_dim)\n",
    "\n",
    "    sum_square_gradients_H = np.zeros_like(H)\n",
    "    sum_square_gradients_A = np.zeros_like(A)\n",
    "    sum_square_gradients_T = np.zeros_like(T)\n",
    "\n",
    "    Hs = [H.copy()]\n",
    "    As = [A.copy()]\n",
    "    Ts = [T.copy()]\n",
    "    \n",
    "    costs = [cost(H, A, T, graph_L, E_np_masked, graph_lam, case)]\n",
    "    HATs = [multiply_case(H, A, T, case)]\n",
    "\n",
    "    # GD procedure\n",
    "    for i in range(num_iter):\n",
    "        del_h, del_a, del_t = mg(H, A, T, graph_L, E_np_masked, graph_lam, case)\n",
    "        sum_square_gradients_H += eps + np.square(del_h)\n",
    "        sum_square_gradients_A += eps + np.square(del_a)\n",
    "        sum_square_gradients_T += eps + np.square(del_t)\n",
    "\n",
    "        lr_h = np.divide(lr, np.sqrt(sum_square_gradients_H))\n",
    "        lr_a = np.divide(lr, np.sqrt(sum_square_gradients_A))\n",
    "        lr_t = np.divide(lr, np.sqrt(sum_square_gradients_T))\n",
    "\n",
    "        H -= lr_h * del_h\n",
    "        A -= lr_a * del_a\n",
    "        T -= lr_t * del_t\n",
    "        # Projection to known values\n",
    "        if H_known is not None:\n",
    "            H = set_known(H, H_known)\n",
    "        if A_known is not None:\n",
    "            A = set_known(A, A_known)\n",
    "        if T_known is not None:\n",
    "            T = set_known(T, T_known)\n",
    "        # Projection to non-negative space\n",
    "        H[H < 0] = 1e-8\n",
    "        A[A < 0] = 1e-8\n",
    "        T[T < 0] = 1e-8\n",
    "\n",
    "        As.append(A.copy())\n",
    "        Ts.append(T.copy())\n",
    "        Hs.append(H.copy())\n",
    "        \n",
    "        costs.append(cost(H, A, T, graph_L, E_np_masked, graph_lam, case))\n",
    "        \n",
    "        HATs.append(multiply_case(H, A, T, case))\n",
    "        if i % 500 == 0:\n",
    "            if dis:\n",
    "                print(cost(H, A, T, graph_L, E_np_masked, graph_lam, case))\n",
    "    return H, A, T, Hs, As, Ts, HATs, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd_L = get_L_NN(sd_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497.906889601\n",
      "101.835314557\n",
      "88.4645646404\n",
      "80.183736121\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "b = 3\n",
    "L_au = get_L_NN(au_agg)\n",
    "case = 2\n",
    "H_au, A_au, T_au, Hs, As, Ts, HATs, costs = learn_HAT_adagrad_graph(case, au_tensor, L_au, a, b, num_iter=2000, lr=0.1, dis=True, random_seed=0, eps=1e-8, penalty_coeff=0.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
